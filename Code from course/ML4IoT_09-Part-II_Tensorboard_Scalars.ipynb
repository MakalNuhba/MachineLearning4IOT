{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Scalar Logging\n",
    "\n",
    "Source: https://www.tensorflow.org/tensorboard/get_started\n",
    "\n",
    "\n",
    "In this notebok, we'll see how to use tensorboard to examine simple scalar metrics from different training runs. Let us start by importing the required modules and add the tensorboard extension to jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 12:20:44.035515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-22 12:20:44.035539: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tb_run = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us download the MNIST handwritten digit recognition dataset and build a simple NN model with the Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 17s 1us/step\n",
      "11501568/11490434 [==============================] - 17s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(512, activation='relu', name='DenseFirst'),\n",
    "        keras.layers.Dense(10, activation='softmax', name='DenseSecond')\n",
    "      ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The TensorBoard callback\n",
    "\n",
    "Let us use the TensorBoard callback to log training information. Note that we use a run counter variable, so that the following training runs are saved to a different tensorboard directory and can be visualized separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 12:21:04.689048: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-22 12:21:04.689120: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-22 12:21:04.689180: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (matteo-Inspiron-7591-2n1): /proc/driver/nvidia/version does not exist\n",
      "2021-12-22 12:21:04.689835: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-22 12:21:04.908257: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1995 - accuracy: 0.9413 - val_loss: 0.0951 - val_accuracy: 0.9703\n",
      "Epoch 2/10\n",
      "  88/1875 [>.............................] - ETA: 3s - loss: 0.0953 - accuracy: 0.9691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 12:21:09.066691: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 96337920 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0796 - accuracy: 0.9756 - val_loss: 0.0791 - val_accuracy: 0.9747\n",
      "Epoch 3/10\n",
      "  86/1875 [>.............................] - ETA: 3s - loss: 0.0444 - accuracy: 0.9847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 12:21:12.648994: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 96337920 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 0.0657 - val_accuracy: 0.9797\n",
      "Epoch 4/10\n",
      "  79/1875 [>.............................] - ETA: 3s - loss: 0.0324 - accuracy: 0.9889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 12:21:16.335877: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 96337920 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0382 - accuracy: 0.9880 - val_loss: 0.0580 - val_accuracy: 0.9805\n",
      "Epoch 5/10\n",
      "  43/1875 [..............................] - ETA: 4s - loss: 0.0179 - accuracy: 0.9942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 12:21:20.229619: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 96337920 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.0946 - val_accuracy: 0.9726\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0788 - val_accuracy: 0.9772\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0766 - val_accuracy: 0.9795\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0715 - val_accuracy: 0.9820\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.0786 - val_accuracy: 0.9806\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0893 - val_accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./tb_log/run_{}'.format(tb_run), histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tb_callback])\n",
    "\n",
    "tb_run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start TensorBoard\n",
    "\n",
    "Start TensorBoard directly in the notebook or from the command line (for that, simply remove the initial % from the following command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a92645ddc947d4ec\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a92645ddc947d4ec\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tb_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Logging\n",
    "\n",
    "Let's try logging some custom scalars from a custom LR scheduler. Let us define a `file_writer` and use it within the LR scheduling function. We also save to a separate `metrics` sub-directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_writer = tf.summary.create_file_writer('./tb_log/run_{}/metrics'.format(tb_run))\n",
    "\n",
    "def my_lr_schedule(epoch, lr):\n",
    "    lr = lr * 0.8\n",
    "    print('My Schedule:', lr, epoch)\n",
    "    with train_writer.as_default():\n",
    "        tf.summary.scalar('learning_rate', data=lr, step=epoch)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Schedule: 0.000800000037997961 0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2135 - accuracy: 0.9385 - val_loss: 0.1042 - val_accuracy: 0.9678 - lr: 8.0000e-04\n",
      "My Schedule: 0.0006400000303983689 1\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0802 - accuracy: 0.9762 - val_loss: 0.0817 - val_accuracy: 0.9744 - lr: 6.4000e-04\n",
      "My Schedule: 0.0005120000336319208 2\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.0640 - val_accuracy: 0.9804 - lr: 5.1200e-04\n",
      "My Schedule: 0.00040960004553198815 3\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 0.0572 - val_accuracy: 0.9808 - lr: 4.0960e-04\n",
      "My Schedule: 0.00032768002711236477 4\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0561 - val_accuracy: 0.9823 - lr: 3.2768e-04\n",
      "My Schedule: 0.0002621440216898918 5\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.0569 - val_accuracy: 0.9817 - lr: 2.6214e-04\n",
      "My Schedule: 0.00020971521735191345 6\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0542 - val_accuracy: 0.9836 - lr: 2.0972e-04\n",
      "My Schedule: 0.00016777217388153076 7\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0546 - val_accuracy: 0.9832 - lr: 1.6777e-04\n",
      "My Schedule: 0.00013421773910522462 8\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0551 - val_accuracy: 0.9829 - lr: 1.3422e-04\n",
      "My Schedule: 0.00010737419361248613 9\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.0549 - val_accuracy: 0.9830 - lr: 1.0737e-04\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./tb_log/run_{}'.format(tb_run), histogram_freq=1)\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(my_lr_schedule)\n",
    "\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tb_callback, lr_callback])\n",
    "tb_run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go back up to the TensorBoard window to see the new logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
